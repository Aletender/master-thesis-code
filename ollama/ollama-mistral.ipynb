{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ollama + RAG + LangChain Demo\n",
    "\n",
    "---\n",
    "## 1. Imports und Setup\n",
    "Hier werden alle benötigten Bibliotheken importiert.\n"
   ],
   "id": "375984b7e116fe48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T13:59:28.146658Z",
     "start_time": "2025-06-07T13:59:28.142157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA  # aktualisierter Import\n",
    "from langchain_community.document_loaders.mongodb import MongodbLoader\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "# Optional: Direktzugriff auf MongoDB, falls benötigt\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n"
   ],
   "id": "e330f9bbe3e96c95",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. LangSmith-Anbindung",
   "id": "78e76a0e481db8af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T13:59:28.175567Z",
     "start_time": "2025-06-07T13:59:28.168156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# .env laden und LangSmith-Umgebungsvariablen setzen\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Lade .env (funktioniert auch im Jupyter Notebook, wenn die Datei im Projekt liegt)\n",
    "load_dotenv(dotenv_path=\"./.env\")\n",
    "\n",
    "# Setze explizit die LangSmith-Variablen für LangChain\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGSMITH_TRACING\", \"true\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\", \"\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\", \"\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\", \"\")\n",
    "\n",
    "# Check, ob die wichtigsten Variablen korrekt geladen wurden\n",
    "print(\"LangSmith-Konfiguration:\")\n",
    "print(\"LANGCHAIN_TRACING_V2:\", os.environ.get(\"LANGCHAIN_TRACING_V2\"))\n",
    "print(\"LANGCHAIN_ENDPOINT:\", os.environ.get(\"LANGCHAIN_ENDPOINT\"))\n",
    "print(\"LANGCHAIN_API_KEY gesetzt:\", bool(os.environ.get(\"LANGCHAIN_API_KEY\")))\n",
    "print(\"LANGCHAIN_PROJECT:\", os.environ.get(\"LANGCHAIN_PROJECT\"))\n"
   ],
   "id": "8101def894002808",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith-Konfiguration:\n",
      "LANGCHAIN_TRACING_V2: true\n",
      "LANGCHAIN_ENDPOINT: https://api.smith.langchain.com\n",
      "LANGCHAIN_API_KEY gesetzt: True\n",
      "LANGCHAIN_PROJECT: Quickstart: LangGraphJS\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. LLM-Instanz für Ollama (Mistral)",
   "id": "906b0fbe854aa7e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:02:12.646739Z",
     "start_time": "2025-06-07T14:02:12.051407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are a helpful assistant for store employees in a pet supply shop.\n",
    "\n",
    "Your main role is to support them in fulfilling Click & Collect orders. This includes:\n",
    "- Understanding and interpreting order details,\n",
    "- Suggesting relevant additional products (e.g. food, accessories, care items),\n",
    "- Preparing customer dialogues for handover (e.g. greeting, product tips, upselling).\n",
    "\n",
    "Always respond in the language the user used in their message. If the user changes the language, adapt accordingly. Be clear, concise, and helpful.\n",
    "\n",
    "Be friendly, competent, and focused on customer satisfaction.\n",
    "\n",
    "The User asks you:\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"mistral\",\n",
    "    temperature=0.3,\n",
    "    top_p=0.3,\n",
    "\n",
    ")\n"
   ],
   "id": "94c06553f75a0968",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Hilfsfunktionen für Dokumentverarbeitung und Vektorstore",
   "id": "b25c966214e70609"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T13:59:28.826185Z",
     "start_time": "2025-06-07T13:59:28.821036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_documents(docs, chunk_size=100, chunk_overlap=10):\n",
    "    splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "def build_vectorstore(docs, embeddings_model=\"mistral\", persist_directory=None):\n",
    "    embeddings = OllamaEmbeddings(model=embeddings_model)\n",
    "    if persist_directory:\n",
    "        return Chroma.from_documents(docs, embedding=embeddings, persist_directory=persist_directory)\n",
    "    else:\n",
    "        return Chroma.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "def build_qa_chain(llm, retriever):\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n"
   ],
   "id": "7e8e05552243038f",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. PDF-Dokument laden und QA-Chain aufbauen",
   "id": "fcacd486180eb4a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T13:59:39.520340Z",
     "start_time": "2025-06-07T13:59:28.855720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "def setup_pdf_chain(pdf_path, llm):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pdf_docs = loader.load()\n",
    "    split_pdf_docs = split_documents(pdf_docs)\n",
    "    if not split_pdf_docs:\n",
    "        print(\"Warnung: Keine PDF-Dokumente zum Indexieren gefunden.\")\n",
    "        return None, None, None\n",
    "    vectorstore_pdf = build_vectorstore(split_pdf_docs)\n",
    "    retriever_pdf = vectorstore_pdf.as_retriever()\n",
    "    qa_chain_pdf = build_qa_chain(llm, retriever_pdf)\n",
    "    return qa_chain_pdf, retriever_pdf, vectorstore_pdf\n",
    "\n",
    "pdf_path = \"ressources/pdf/Arbeitsanweisung_Tierbedarfsladen.pdf\"\n",
    "qa_chain_pdf, retriever_pdf, vectorstore_pdf = setup_pdf_chain(pdf_path, llm)\n"
   ],
   "id": "76e7772e34ddccb4",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. MongoDB-Dokumente laden und QA-Chain aufbauen",
   "id": "916c982dbf5a4293"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_mongo_docs():\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    collection = client[\"thesis\"][\"tasks\"]\n",
    "    raw_docs = list(collection.find())\n",
    "\n",
    "    def format_task(doc):\n",
    "        products_text = \"\\n\".join([f\"- {p['quantity']}x {p['sku']}\" for p in doc.get(\"products\", [])])\n",
    "        return f\"\"\"\n",
    "Aufgabe {doc.get(\"taskId\", \"Unbekannt\")} für {doc.get(\"customerName\", \"Unbekannt\")} ({doc.get(\"customerId\")}):\n",
    "Status: {doc.get(\"status\")}\n",
    "Zeitraum: {doc.get(\"startDate\")} bis {doc.get(\"endDate\")}\n",
    "Warnhinweis: {\"ja\" if doc.get(\"hasWarning\") else \"nein\"}\n",
    "Produkte:\n",
    "{products_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    mongo_docs = [\n",
    "        Document(\n",
    "            page_content=format_task(doc),\n",
    "            metadata={\"_id\": str(doc[\"_id\"])}\n",
    "        )\n",
    "        for doc in raw_docs\n",
    "    ]\n",
    "    return mongo_docs\n",
    "\n",
    "def setup_mongo_chain(llm):\n",
    "    mongo_docs = load_mongo_docs()\n",
    "    split_docs = split_documents(mongo_docs, chunk_size=500, chunk_overlap=50)\n",
    "    if not split_docs:\n",
    "        print(\"Keine Dokumente zum Indexieren gefunden.\")\n",
    "        return None, None, None\n",
    "    vectorstore = build_vectorstore(split_docs, persist_directory=\"./chroma_mongo\")\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    qa_chain = build_qa_chain(llm, retriever)\n",
    "    return qa_chain, retriever, vectorstore\n",
    "\n",
    "qa_chain_mongo, retriever_mongo, vectorstore_mongo = setup_mongo_chain(llm)\n"
   ],
   "id": "e4673f6166f7121"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Agent mit Tools für PDF- und MongoDB-QA",
   "id": "16e3a807d43f65dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "\n",
    "tools = []\n",
    "if qa_chain_pdf:\n",
    "    tools.append(\n",
    "        Tool(\n",
    "            name=\"PDF QA\",\n",
    "            func=lambda input: qa_chain_pdf.invoke({\"query\": input})[\"result\"],\n",
    "            description=\"Beantworte Fragen zu den Inhalten der PDF-Arbeitsanweisung.\"\n",
    "        )\n",
    "    )\n",
    "if qa_chain_mongo:\n",
    "    tools.append(\n",
    "        Tool(\n",
    "            name=\"MongoDB QA\",\n",
    "            func=lambda input: qa_chain_mongo.invoke({\"query\": input})[\"result\"],\n",
    "            description=\"Beantworte Fragen zu Aufgaben aus der MongoDB.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "if tools:\n",
    "    agent = initialize_agent(\n",
    "        tools=tools,\n",
    "        llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "    )\n",
    "else:\n",
    "    agent = None\n",
    "    print(\"Keine Tools für den Agenten verfügbar.\")\n"
   ],
   "id": "6afd1ccf3776d573"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Beispiel-Query an den Agenten",
   "id": "986b639cd19fa529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if agent:\n",
    "    query = \"Welche Aufgabe ist die neueste? Antworte auf Deutsch.\"\n",
    "    print(\"Agent-Antwort:\", agent.invoke(query))\n",
    "else:\n",
    "    print(\"Agent konnte nicht initialisiert werden.\")\n"
   ],
   "id": "4ab764225d74f87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Schritt 1: Trainingsdaten für LoRa-Tuning vorbereiten\n",
    "import json\n",
    "\n",
    "train_data = [\n",
    "    {\n",
    "        \"instruction\": \"Was ist Click & Collect?\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"Click & Collect bedeutet, dass Kunden online bestellen und die Ware im Laden abholen.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Nenne drei Vorteile von Click & Collect.\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"1. Schnelle Abholung\\n2. Keine Versandkosten\\n3. Persönliche Beratung im Laden\"\n",
    "    }\n",
    "    # ...weitere Beispiele ergänzen...\n",
    "]\n",
    "\n",
    "with open(\"lora-train-data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in train_data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Trainingsdaten gespeichert: lora-train-data.jsonl\")\n"
   ],
   "id": "9b973def2327e536"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Schritt 2: LoRa-Tuning mit Ollama CLI (im Terminal ausführen, nicht im Notebook)\n",
    "# !ollama tune mistral lora-train-data.jsonl --output mistral-lora\n"
   ],
   "id": "bb5e917a34fd81c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Schritt 3: Das getunte Modell laden\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_lora = ChatOllama(\n",
    "    model=\"mistral-lora\",\n",
    "    temperature=0.3,\n",
    "    top_p=0.3,\n",
    ")\n"
   ],
   "id": "364af63f14463b71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Schritt 4: Vergleich Basismodell vs. LoRa-Modell\n",
    "test_prompt = \"Was ist Click & Collect?\"\n",
    "\n",
    "print(\"Antwort Basismodell:\")\n",
    "print(llm.invoke(test_prompt))\n",
    "\n",
    "print(\"\\nAntwort LoRa-getuntes Modell:\")\n",
    "print(llm_lora.invoke(test_prompt))\n"
   ],
   "id": "95e32a3314687392"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Schritt 5: Chains und Agenten mit LoRa-Modell testen\n",
    "qa_chain_pdf_lora, retriever_pdf_lora, vectorstore_pdf_lora = setup_pdf_chain(pdf_path, llm_lora)\n",
    "qa_chain_mongo_lora, retriever_mongo_lora, vectorstore_mongo_lora = setup_mongo_chain(llm_lora)\n",
    "\n",
    "tools_lora = []\n",
    "if qa_chain_pdf_lora:\n",
    "    tools_lora.append(\n",
    "        Tool(\n",
    "            name=\"PDF QA (LoRa)\",\n",
    "            func=lambda input: qa_chain_pdf_lora.invoke({\"query\": input})[\"result\"],\n",
    "            description=\"Beantworte Fragen zu den Inhalten der PDF-Arbeitsanweisung (LoRa-getuntes Modell).\"\n",
    "        )\n",
    "    )\n",
    "if qa_chain_mongo_lora:\n",
    "    tools_lora.append(\n",
    "        Tool(\n",
    "            name=\"MongoDB QA (LoRa)\",\n",
    "            func=lambda input: qa_chain_mongo_lora.invoke({\"query\": input})[\"result\"],\n",
    "            description=\"Beantworte Fragen zu Aufgaben aus der MongoDB (LoRa-getuntes Modell).\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "if tools_lora:\n",
    "    agent_lora = initialize_agent(\n",
    "        tools=tools_lora,\n",
    "        llm=llm_lora,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(\"LoRa-Agent bereit.\")\n",
    "else:\n",
    "    agent_lora = None\n",
    "    print(\"Keine Tools für den LoRa-Agenten verfügbar.\")\n"
   ],
   "id": "2327d30c9571e617"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Beispiel-Query an den LoRa-Agenten\n",
    "if agent_lora:\n",
    "    query = \"Welche Aufgabe ist die neueste? Antworte auf Deutsch.\"\n",
    "    print(\"LoRa-Agent-Antwort:\", agent_lora.invoke(query))\n",
    "else:\n",
    "    print(\"LoRa-Agent konnte nicht initialisiert werden.\")\n"
   ],
   "id": "a982990331946c1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53efc60cf0dd7cdd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
